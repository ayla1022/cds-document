---
title: 客户端 timewait 过多解决方案    
date: 2021-11-25 12:22:01
permalink: /pages/1233029/
article: true
---


#### 背景

在压测负载均衡 HaProxy 时，会遇到一些客户端 timewait 过多，端口被快速占满，导致 connect 失败的问题。

#### Linux 参数介绍

- tcp_timestamps ： 是否开启 tcp timestamps 选项，缺省是开启状态，timestamps 是在 tcp 三次握手过程中协商的，任意一方不支持，该连接就不会使用 timestamps 选项。
- tcp_tw_recycle ： 是否开启tcp_tw_recycle选项，缺省是关闭状态且关联tcp_timestamps选项，如果需要开启tcp_tw_recycle选项，必须先开启tcp_timestamps选项。它用来快速回收TIME_WAIT连接，不过如果在NAT环境下会引发问题。
- tcp_tw_reuse ： 默认值2表示仅环回流量开启，0表示关闭，1表示开启，它用于复用TIME_WAIT连接，通常认为tcp_tw_reuse比tcp_tw_recycle更安全一些，这是因为一来TIME_WAIT创建时间必须超过一秒才可能会被复用；二来只有连接的时间戳是递增的时候才会被复用。

#### 原因分析

客户端 timewait 太多，是因为客户端主动断开连接，客户端每断开一个连接，该连接都会进入 timewait 状态，默认60s超时回收。一般情况下，遇到这种场景时，客户会选择打开 `tcp_tw_recycle` 和 `tcp_tw_reuse` 两个参数，便于回收 timewait 状态连接。

然而当前负载均衡 HaProxy 没有打开 `tcp_timestamps` 选项，导致客户端打开的 `tcp_tw_recycle` 和 `tcp_tw_reuse` 都不会生效，不能快速回收 timewait 状态连接。下面会解释几个 Linux 参数的含义和负载均衡 HaProxy 不能开启 `tcp_timestamps` 的原因。

1. tcp_tw_recycle 和 tcp_tw_reuse 只有在 tcp_timestamps 打开时才会生效。

2. tcp_timestamps 和 tcp_tw_recycle 是不能同时打开的，因为公网客户端经过 NAT 网关访问服务器，会存在问题，原因如下：
   tcp_tw_recycle/tcp_timestamps 都开启的条件下，60s内同一源 IP 主机的 socket connect 请求中的 timestamp 必须是递增的。以2.6.32内核为例，具体实现如下：

   ```c++
   if (tmp_opt.saw_tstamp && tcp_death_row.sysctl_tw_recycle && (dst = inet_csk_route_req(sk, req)) != NULL &&
             (peer = rt_get_peer((struct rtable *)dst)) != NULL &&
            peer->v4daddr == saddr) 
   {
             if (get_seconds() < peer->tcp_ts_stamp + TCP_PAWS_MSL &&
               (s32)(peer->tcp_ts - req->ts_recent) >
                        TCP_PAWS_WINDOW) {
               NET_INC_STATS_BH(sock_net(sk), LINUX_MIB_PAWSPASSIVEREJECTED);
                goto drop_and_release;
             }
   }
   ```
   
   
   
   > **说明**：
   >
   > tmp_opt.saw_tstamp：该 socket 支持 tcp_timestamp。
   > sysctl_tw_recycle：本机系统开启 tcp_tw_recycle 选项。
   > TCP_PAWS_MSL：60s，该条件判断表示该源 IP 的上次 tcp 通讯发生在60s内。
   > TCP_PAWS_WINDOW：1，该条件判断表示该源 IP 的上次 tcp 通讯的 timestamp 大于本次 tcp。
   
3. 负载均衡 HaProxy 关闭了 tcp_timestamps 原因，因为公网客户端经过 NAT 网关访问服务器，可能会存在问题，如下例：
   a) 某五元组还是 time_wait 状态。NAT网关对端口的分配策略，2MSL 内复用了同个五元组，发来 syn 包。
   b) 在开启 tcp_timestamps 情况下，同时满足如下两个条件，会丢弃该 syn 包（因为开启了时间戳选项，认为是老包）。

   + 上次时间戳 > 本次时间戳。
   + 24天内收过包（时间戳字段是32位，Linux 默认1ms更新一次时间戳，24天会发生时间戳回绕）。

   备注：在移动端该问题更为明显，因为客户端都是在运营商NAT网关下面共享有限的公网 IP，五元组还可能在2MSL内被复用，不同客户端传来的时间戳不能保证是递增的。

   以2.6.32内核为例， tcp_time_wait()代码片段具体实现如下：

   ```c++
   if (tcp_death_row.sysctl_tw_recycle && tp->rx_opt.ts_recent_stamp)
         recycle_ok = icsk->icsk_af_ops->remember_stamp(sk);
         ......
   
         if (timeo < rto)
            timeo = rto;
   
         if (recycle_ok) {
           tw->tw_timeout = rto;
         } else {
           tw->tw_timeout = TCP_TIMEWAIT_LEN;
            if (state == TCP_TIME_WAIT)
               timeo = TCP_TIMEWAIT_LEN;
         }
        inet_twsk_schedule(tw, &tcp_death_row, timeo, TCP_TIMEWAIT_LEN);
   ```
   
   
   
   > **说明**：
   >
   > timestamp和tw_recycle同时开启的条件下，timewait状态socket释放的超时时间和rto相关；否则，超时时间为TCP_TIMEWAIT_LEN（即60s）。

#### 解决方案

客户端 Timewait 过多问题，有如下解决方案：

1. HTTP 使用短连接（Connection: close），这时由负载均衡 HaProxy 主动关闭连接，客户端不会产生 timewait。
2. 如果场景需要使用长连接，可以打开 socket 的 SO_LINGER 选项，使用 rst 关闭连接，避免进入 timewait 状态，达到快速回收端口的目的。
